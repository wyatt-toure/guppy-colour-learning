---
title: "Guppy colour learning - experiment 2 data preparation and analysis"
author: "M. Wyatt Toure"
output:
  bookdown::html_document2:
    number_sections: false
    split_by: section
---

Date of last update: `r format(Sys.Date(), '%b %d %Y')`

```{r library-prep, include=FALSE}
# Loading required packages
library(lme4)
library(tidyr)
library(lmerTest)
library(ggplot2)
library(ggpubr)
library(DHARMa)
library(dplyr)
library(effects)
library(broom)
library(broom.mixed)
library(knitr)
library(emmeans)
library(report)
library(cowplot)
library(tidyext)
library(glmmTMB)
library(MASS)
library(googledrive)
library(stringr)
source("R/format-p-value.R")
source("R/rename-lme4-model.R")
source("R/geom-flat-violin.R")
source("R/read-ethovision-data.R")
```

## Data preparation 

In this section we detail the steps taken to process the raw data produced by
processing video footage with automated tracking from Noldus EthoVision. The raw
data can be found in the [`data/experiment-2-raw-data/`]() directory. They are
composed of `.xlsx` files exported from EthoVision XT Version 11. Each trial is
in a separate `.xlsx` file. 

To prepare the data first we download the raw data files from the Google drive
folder they are stored in. We make use of the tidyverse package `googledrive` to
do this. We put `googledrive` into a de-authorized state so we can access public
Google drive resources without a Google sign-in. We then get the list of files that
are present in the Google drive directory and use a `for()` loop which downloads
each file using the `drive_download()` function. The data are downloaded to the
`data/experiment-2-raw-data/` directory.

```{r data-download, message=FALSE, warning=FALSE}
# Downloading data from Google drive 

## Put googledrive into a de-authorized state 
drive_deauth()

## Store link to data folder 
data_folder <- "https://drive.google.com/drive/folders/1A8NRlBMQ-BfkgNHzEpmw6hEbgePJncLj?usp=sharing"

## Get id for data folder
data_folder_id <- drive_get(as_id(data_folder))

## Store the list of file names and ids found in the data folder
data_files <- drive_ls(data_folder_id)

## Loop through and download each file
for (file_x in 1:length(data_files$name)) {
      drive_download(
        as_id(data_files$id[file_x]),
        path = str_c("data/experiment-2-raw-data/",data_files$name[file_x]),
        overwrite = TRUE)
}
```

Next we read in and format the raw `.xlsx` output from EthoVision using one of
my custom functions, `read_and_format_ethovision_data()`. The code for this can
be seen
[here](https://github.com/wyatt-toure/guppy-colour-learning-project/blob/main/R/read-ethovision-data.R).
The full processed data are available in the file
[`colour-learning-experiment-2-full-data.csv`]().

```{r data-read, message=FALSE}
# Reading in Data
full_data <- read_and_format_ethovision_data("data/experiment-2-raw-data/")
```

Next we add the rewarding object colour treatments that were established *a
priori* in the file [`datasheet-experiment-2.Rmd`]().

```{r data-prep-2}
## Assigning treatments
full_data <- full_data %>%
  mutate(
    rewarding.object.colour =
      case_when(
        id == "1a" ~ "blue",
        id == "1b" ~ "green",
        id == "2a" ~ "blue",
        id == "2b" ~ "blue",
        id == "3a" ~ "blue",
        id == "3b" ~ "green",
        id == "4a" ~ "green",
        id == "4b" ~ "green",
        id == "5a" ~ "green",
        id == "5b" ~ "blue",
        id == "6a" ~ "green",
        id == "6b" ~ "green",
        id == "7a" ~ "blue",
        id == "7b" ~ "blue",
        id == "8a" ~ "green",
        id == "8b" ~ "blue"
      )
  )
```

All the variables for the data set are read in as characters due to the
`read_excel()` call in `read_and_format_ethovision_data()`, so we need to
convert them to their appropriate data structures for the analysis. Variables
are converted to either factors or numerics where appropriate.

```{r data-prep-3}
# Converting variables

## Factors
Factors <- c("ate", "id", "object.side", "rewarding.object.colour", "object.pair")
full_data[Factors] <- lapply(full_data[Factors], as.factor)

## Numeric
Numerics <- c(
  "trial",
  "left.object.visits", "time.with.left.object",
  "left.object.latency", "right.object.visits",
  "time.with.right.object", "right.object.latency",
  "periphery.visits", "time.in.periphery",
  "latency.to.periphery", "center.visits",
  "time.in.center", "latency.to.center",
  "distance.moved", "mean.velocity"
)
full_data[Numerics] <- lapply(full_data[Numerics], as.numeric)
```

New variables need to be created from the variables we have in the raw data
sheets. First we need to invert the object side because the camera image is
reversed from the perspective of the experimenter. We then create the variables
`time.with.trained.object` and `time.with.untrained.object` by identifying
whether the left or right object is the reward object.

The preference metrics `green.object.preference` and
`rewarding.object.preference` are created by subtracting the time spent near the
blue object from the time spent near the green object and subtracting the time
spent near the untrained object from the time spent near the trained object
respectively.

`time.with.both.objects` is obtained by summing the time spent near the left and
the right object. `total.time` is obtained by summing the `time.in.periphery`
with the `time.in.center`. `total.time` should be close to 300 since trials
last 5 minutes (300 seconds).

We also add the variable trial type to identify whether a trial is a test trial
(unreinforced) or training trial (reinforced).

```{r data-prep-4, warning=FALSE, message=FALSE}
# Creating new variables

## Inverting object side
full_data <- full_data %>%
  mutate(
    reward.object.side =
      as.factor(
        case_when(
          object.side == "left" ~ "right",
          object.side == "right" ~ "left"
        )
      )
  )

## Time with trained object
full_data <- full_data %>%
  mutate(
    time.with.trained.object =
      case_when(
        reward.object.side == "left" ~ time.with.left.object,
        reward.object.side == "right" ~ time.with.right.object
      )
  )

## Time with untrained object
full_data <- full_data %>%
  mutate(
    time.with.untrained.object =
      case_when(
        reward.object.side == "left" ~ time.with.right.object,
        reward.object.side == "right" ~ time.with.left.object
      )
  )

## Green object preference
full_data <- full_data %>%
  mutate(
    green.object.preference =
      case_when(
        rewarding.object.colour == "green" ~ (time.with.trained.object - time.with.untrained.object),
        rewarding.object.colour == "blue" ~ (time.with.untrained.object - time.with.trained.object)
      )
  )

## Rewarding object preference
full_data <- full_data %>%
  group_by(id) %>%
  mutate(
    rewarding.object.preference =
      time.with.trained.object - time.with.untrained.object
  )

## Proportionanl Rewarding object preference
full_data <- full_data %>%
  group_by(id) %>%
  mutate(
    prop.rewarding.object.preference =
      time.with.trained.object/(time.with.trained.object + time.with.untrained.object)
  )

## Time with both objects
full_data <- full_data %>%
  mutate(
    time.with.both.objects =
      time.with.left.object + time.with.right.object
  )

## Total time
full_data <- full_data %>%
  mutate(
    total.time =
      time.in.center + time.in.periphery
  )

## Trial type
full_data <- full_data %>%
  mutate(
    trial.type =
      as.factor(
        case_when(
          trial == 0 | trial == 21 ~ "test",
          trial > 0 & trial < 21 ~ "training"
        )
      )
  )
```

Here, we create subsets of the full data set that are restricted to the training
trials (reinforced), the test trials (unreinforced), and the initial test trial
(unreinforced).

```{r data-prep-6, warning=FALSE, message=FALSE}
# Restrict data to training data
training_data <- full_data %>%
  filter(trial.type == "training")

# Restrict data to only the baseline and re-test data
test_data <- full_data %>%
  filter(trial.type == "test")

# Restrict data to only the baseline data
baseline_data <- full_data %>%
  filter(trial == 0)

# Change trial to factor
test_data$trial <- as.factor(test_data$trial)
baseline_data$trial <- as.factor(baseline_data$trial)
```

Finally we export the full data set as a `.csv` file to future proof the full
data sheet in a plain text, machine-readable format.

```{r data-prep-7}
write.csv(full_data, file = "data/colour-learning-experiment-2-full-data.csv")
```

## Models

We analysed the data from our experiment using linear mixed effect and
generalized linear mixed effect models with the `lmer()` and `glmer()` functions
from the `lme4` package. P-values and effective degrees of freedom were obtained
using the `lmerTest` package. Model residuals were checked they met
distributional assumptions with the `DHARMa` package, you can click the 'See
Model Residuals' button below the model formulas to see the residual diagnostic
plots produced by `DHARMa` for that particular model.

</br>

### Model 1 -  Preference for the green object at baseline

This first model contains the data for all individual guppies. We looked at the
green object preference of all guppies in an intercept only model to see if the
green object preference at baseline was significantly different from zero.
`green.object.preference` is the time spent near the green object subtracted by
the time spent near the blue object.

```{r model-1, echo=TRUE}
baseline_data_model <-
  lm(green.object.preference ~ 1,
    data = baseline_data
  )
```

<button class="btn btn-primary" data-toggle="collapse" data-target="#BlockName"> See Model 1 Residuals </button>  
<div id="BlockName" class="collapse"> 

```{r, echo=FALSE, message=FALSE}
simulationOutput <- simulateResiduals(fittedModel = baseline_data_model)
plot(simulationOutput)

# Saving plot to figs directory
ggsave(
  filename = "exp-2-model-1-residual-plot.png",
  plot = (plot(simulationOutput)),
  path = "figs/exp-2/exp-2-residual-plots",
  device = "png",
  dpi = 300
)
```

</div>

##### Result

```{r tidying-model-1, echo=FALSE, message=FALSE}
# Setting table row names
baseline_table_row_name_vec <- c("Intercept")

# Converting data frame to tibble
tidy_baseline_model <- broom.mixed::tidy(baseline_data_model)

# Changing tibble header names
tidy_baseline_model <- rename_tidy_lme4_cols(tidy_baseline_model)

# Changing tibble row names
tidy_baseline_model[1:1, 1] <- baseline_table_row_name_vec
```

```{r,  results=TRUE, echo=FALSE}
knitr::kable(tidy_baseline_model %>%
  mutate_if(is.numeric, round, digits = 3))
```

```{r baseline-pref-plot, echo=FALSE, message=FALSE, echo=FALSE, fig.cap="Preference for the green object relative to the blue object across all guppies at baseline. Negative values represent more time spent with the blue object, positive values indicate more time spent with the green object. Data are means Â± 95% CI", fig.id="baseline-pref-plot",  warning=FALSE, message=FALSE}
###### Baseline green object preference plot ######
baseline_data_x_axis_label <- "Initial Test"
ggplot(
  baseline_data,
  aes(
    x = trial,
    y = green.object.preference
  )
) +
  theme_classic() +
  ylab("Green object preference (sec)") +
  xlab("") +
  theme(
    legend.position = "none",
    axis.text = element_text(size = 14),
    axis.title = element_text(size = 14, face = "bold"),
    plot.title = element_text(size = 16, hjust = 0.5)
  ) +
  geom_hline(yintercept = 0, linetype = "dashed", alpha = 0.5) +
  geom_jitter(width = 0.04, alpha = 0.3) +
  stat_summary(
    geom = "point",
    fun = "mean",
    size = 4.5,
    shape = 15
  ) +
  stat_summary(
    geom = "errorbar",
    fun.data = "mean_ci", position = position_dodge(width = 0), width = 0.1
  ) +
  scale_x_discrete(labels = baseline_data_x_axis_label)

ggsave(
  filename = "exp-2-model-1-baseline-data-plot.png",
  path = "figs/exp-2",
  device = "png",
  dpi = 300
)
```

***

### Preference for the rewarding object during training

```{r, echo=FALSE}
###### Time with rewarding object plot during training ######
ggplot(
  full_data,
  aes(
    x = as.factor(trial),
    y = green.object.preference,
    color = rewarding.object.colour,
    shape = rewarding.object.colour,
    linetype = rewarding.object.colour
  )
) +
  theme_minimal() +
  ylab("Green object preference (sec)") +
  xlab("Trial") +
  labs(col = "Rewarding object colour") +
  theme(
    legend.position = "none",
    axis.text = element_text(size = 14),
    axis.title = element_text(size = 14, face = "bold"),
    plot.title = element_text(size = 16, hjust = 0.5)
  ) +
  scale_color_manual(values = c("#2980b9", "#27ae60")) +
  scale_linetype_manual(values = c("longdash", "solid")) +
  scale_shape_manual(values = c(15, 16)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point(alpha = 0.3) +
  geom_line(aes(group = id), alpha = 0.3) +
  stat_summary(geom = "point", fun = "mean", size = 4.5) +
  stat_summary(
    geom = "errorbar",
    fun.data = "mean_se",
    position = position_dodge(width = 0),
    width = 0.1,
    alpha = 0.8,
    linetype = "solid"
  )
```

```{r, message=FALSE}
full_data %>% 
  group_by(trial, rewarding.object.colour) %>% 
  summarise(mean(rewarding.object.preference)) %>% 
  mutate_if(is.numeric, round, digits = 3) %>% 
  kable() 
```



```{r, echo=FALSE}
ggplot(
  full_data,
  aes(
    x = as.factor(trial),
    y = distance.moved
  )
) +
  theme_minimal() +
  geom_point(alpha = 0.3) +
  geom_line(aes(group=id), alpha = 0.2) +
  stat_summary(geom = "point", fun = "mean", size = 4.5)
```

```{r feeding-data-prep, include = FALSE}
#### Get feeding data #####
# Group by ID and count the number of sessions in which an individual ate
feeding <- full_data %>%
  group_by(id) %>%
  count(feeding.count = ate == "yes")

# Remove NAs from this
feeding <- na.omit(feeding)

# Count only the yeses
feeding <- feeding %>%
  filter(feeding.count == "TRUE")

# Remove the column feeding.count to keep only the counts
feeding <- feeding %>%
  dplyr::select(-feeding.count)

# Add the feeding values to the main data frame so I can get treatment IDs
my_feeding_data <- left_join(baseline_data, feeding, by = "id")

# Replace NAs with 0, rename n to feeding count, and extract id, feeding count,
# and rewarding object colour treatment
my_feeding_data <- my_feeding_data %>%
  replace_na(list(n = 0)) %>%
  rename(feeding.count = n) %>%
  dplyr::select(id, feeding.count, rewarding.object.colour)
```



